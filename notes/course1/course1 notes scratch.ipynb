{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy rundown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "s = np.array(5)\n",
    "print(s)\n",
    "print(s.shape)\n",
    "x = s + 3\n",
    "y = 8\n",
    "print(\"s type: %s\" % type(s))\n",
    "print(\"x=%d and is of type: %s\" % (x,type(x)))\n",
    "print(\"y=%d and is of type: %s\" % (y,type(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vectors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v=np.array([1,2,3])\n",
    "print(\"v = %s and has shape = %s\" % (v, v.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tuple : a finite, ordered sequence of elements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_tuple=(123, 532, 'whaddup chaningas!') and is of type <class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "my_tuple = 123, 532, \"whaddup chaningas!\"\n",
    "print(\"my_tuple=%s and is of type %s\" % (my_tuple,type(my_tuple)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tuples are immutable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-b4c0395966fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmy_tuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"something else\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'tuple' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "my_tuple[0] = \"something else\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(v.shape)\n",
    "print(v.reshape(1,3).shape)\n",
    "print(v[None, :].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dot products only work for vectors of the same length "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "v = [1,2,3]\n",
    "print(type(v))\n",
    "v_nd = np.ndarray(v)\n",
    "print(np.min(v_nd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_inputs(inputs):\n",
    "    # TODO: create a 2-dimensional ndarray from the given 1-dimensional list;\n",
    "    #       assign it to input_array\n",
    "    input_array = np.array(inputs)\n",
    "    \n",
    "    # TODO: find the minimum value in input_array and subtract that\n",
    "    #       value from all the elements of input_array. Store the\n",
    "    #       result in inputs_minus_min\n",
    "    inputs_minus_min = input_array - np.min(input_array)\n",
    "\n",
    "    # TODO: find the maximum value in inputs_minus_min and divide\n",
    "    #       all of the values in inputs_minus_min by the maximum value.\n",
    "    #       Store the results in inputs_div_max.\n",
    "    inputs_div_max = inputs_minus_min / np.max(inputs_minus_min)\n",
    "\n",
    "    # return the three arrays we've created\n",
    "    return input_array, inputs_minus_min, inputs_div_max\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "[[ 0.     0.375  1.   ]]\n"
     ]
    }
   ],
   "source": [
    "some_arr = [-1,2,7]\n",
    "a,b,c = prepare_inputs([some_arr])\n",
    "print(a.shape[0])\n",
    "print(b.ndim)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.]]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ndarray(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.]]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_tuple = 1,2,3\n",
    "np.ndarray(v_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply_inputs(m1, m2):\n",
    "    # TODO: Check the shapes of the matrices m1 and m2. \n",
    "    #       m1 and m2 will be ndarray objects.\n",
    "    #\n",
    "    #       Return False if the shapes cannot be used for matrix\n",
    "    #       multiplication. You may not use a transpose\n",
    "    if m1.shape[1] != m2.shape[0] and m1.shape[0] != m2.shape[1]: return False\n",
    "\n",
    "    # TODO: If you have not returned False, then calculate the matrix product\n",
    "    #       of m1 and m2 and return it. Do not use a transpose,\n",
    "    #       but you swap their order if necessary\n",
    "    if m1.shape[1] == m2.shape[0]:\n",
    "        return np.matmul(m1,m2)\n",
    "    else:\n",
    "        return np.matmul(m2,m1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = np.array([[1,2],[1,2]])\n",
    "m2 = np.array([[1,2],[2,3],[444,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [1 2]]\n",
      "[[  1   2]\n",
      " [  2   3]\n",
      " [444   5]]\n",
      "[[  3   6]\n",
      " [  5  10]\n",
      " [449 898]]\n"
     ]
    }
   ],
   "source": [
    "print(m1)\n",
    "print(m2)\n",
    "print(multiply_inputs(m1,m2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'avg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-99-ddfb6875343e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mavg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'avg'"
     ]
    }
   ],
   "source": [
    "np.avg(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(X, W, b):\n",
    "    return stepFunction((np.matmul(X,W)+b)[0])\n",
    "\n",
    "# TODO: Fill in the code below to implement the perceptron trick.\n",
    "# The function should receive as inputs the data X, the labels y,\n",
    "# the weights W (as an array), and the bias b,\n",
    "# update the weights and bias W, b, according to the perceptron algorithm,\n",
    "# and return W and b.\n",
    "def perceptronStep(X, y, W, b, learn_rate = 0.01):\n",
    "    # Fill in code\n",
    "    y_hat = np.dot(X,W) + b \n",
    "    m = len(y)\n",
    "    for index in range(m):\n",
    "        if y[index] == 0 and y_hat[index] >= 0:\n",
    "            W[0] = W[0] + learn_rate * X[index][0]\n",
    "            W[1] = W[1] + learn_rate * X[index][1]\n",
    "            b = b + learn_rate\n",
    "        if y[index] == 1 and y_hat[index] < 0:\n",
    "            W[0] = W[0] - learn_rate * X[index][0]\n",
    "            W[1] = W[1] - learn_rate * X[index][1]\n",
    "            b = b - learn_rate\n",
    "    \n",
    "    return W, b\n",
    "\n",
    "# This function runs the perceptron algorithm repeatedly on the dataset,\n",
    "# and returns a few of the boundary lines obtained in the iterations,\n",
    "# for plotting purposes.\n",
    "# Feel free to play with the learning rate and the num_epochs,\n",
    "# and see your results plotted below.\n",
    "def trainPerceptronAlgorithm(X, y, learn_rate = 0.01, num_epochs = 25):\n",
    "    x_min, x_max = min(X.T[0]), max(X.T[0])\n",
    "    y_min, y_max = min(X.T[1]), max(X.T[1])\n",
    "    W = np.array(np.random.rand(2,1))\n",
    "    b = np.random.rand(1)[0] + x_max\n",
    "    # These are the solution lines that get plotted below.\n",
    "    boundary_lines = []\n",
    "    for i in range(num_epochs):\n",
    "        # In each epoch, we apply the perceptron step.\n",
    "        W, b = perceptronStep(X, y, W, b, learn_rate)\n",
    "        boundary_lines.append((-W[0]/W[1], -b/W[1]))\n",
    "    return boundary_linesnp.mean(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make sure that prediction outputs are not dependent on each other = one hot encoding \n",
    "\n",
    "maximum likelihood = give existing labels the highest probability of correct output   , and pick the best model \n",
    "\n",
    "cross entropy = the sum of (logarithms)*(-1) of the probabilities aka the negative log-likelihood\n",
    "   * the lower the cross-entropy, the better the predictions\n",
    "   \n",
    "\n",
    "the lower the probability of a single prediction = x yields a large -ln(x), so sum(-ln(X)) where X is a bunch of bad probabilities is a large value, so we want to minize the value of sum(-ln(X))\n",
    "\n",
    "\n",
    "better to minimize cross entropy than to maximize likelihood aka min(sum(-ln(X))) is better than product(X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross entropy implementation\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Write a function that takes as input two lists Y, P,\n",
    "# and returns the float corresponding to their cross-entropy.\n",
    "def cross_entropy(Y, P):\n",
    "    Y = np.asarray(Y)\n",
    "    P = np.asarray(P)\n",
    "    ce = -np.sum(np.multiply(Y, np.log(P)) + np.multiply((1-Y), np.log(1-P)))\n",
    "    return ce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important concept: Measuring the quality of a NN\n",
    "#### Train of thought:\n",
    "We have a set of inputs, outputs, and a model, so the question is: how do we tune the parameters in our model so that we can predict the outputs of futures inputs?\n",
    "\n",
    "A measure of error $E$ will show us **how well** the model predictions fare on the outputs across an entire dataset.\n",
    "\n",
    "The first thought is to do $E = \\sum\\limits_{m}(y - \\hat{y})$, but we choose $E = \\dfrac{1}{2}\\sum\\limits_{m}(y - \\hat{y})^2$ (SSE) for a couple of reasons:\n",
    "* the error is always positive\n",
    "* the square penalizes outliers (bad predictions) more \n",
    "* it'll help with our weight updates later on (i.e. $w_i = w_i + \\Delta w_i)$\n",
    "* the $\\dfrac{1}{2}$ makes the derivative easier to work with later on\n",
    "\n",
    "Now, we strive to create the **highest** quality of a neural network that can predict the outputs with the highest possible accuracy (100%) so we'd want to minimize the error, or $\\min E$. And, since the parameters we'll be tuning are the weights $W$ (remember in forward prop, $W$ are all the weights we use to calculate our prediction $\\hat{y}$ when given input data. Also, this is not including hyperparameters: initalization, activation functions, etc.), we have: $\\min\\limits_{W} E$.\n",
    "\n",
    "So, what is  $\\min\\limits_{W} E = ?$\n",
    "\n",
    "Sometimes it can be solved analytically, but MOSTLY it can't! So, we'll need to solve for it iteratively, where the error is smaller with each successive iteration we reach a sufficient condition/threshold, through optimization algorithms. Most popular optim algo in use right now is gradient descent.\n",
    "\n",
    "Gradient descent is as follows:\n",
    "\n",
    "Remember that $\\hat{y} = f(\\sum w_ix_i) \\rightarrow E = \\dfrac{1}{2}\\sum\\limits_{\\mu}(y - f(\\sum w_ix_i))^2$. Let's say our error for varying values of $W$ can be represented as such: \n",
    "\n",
    "![alt text](https://upload.wikimedia.org/wikipedia/commons/6/6d/Error_surface_of_a_linear_neuron_with_two_input_weights.png)\n",
    "\n",
    "We'd want to reach the bottom of this bowl so that we __minimize__ the error. Since $f(\\sum w_ix_i)= f(W,X)$ and $X$ is a predetermined set of inputs, we'll have to tune $W$ to move ourselves along the graph. Let's call a single descent step of this movement $\\Delta W$ or, equivalently, $\\Delta w, \\forall w \\in W$.\n",
    "\n",
    "Now, it turns out that this single descent step $\\Delta W = -\\nabla E(W,X)$, or the negative of the gradient of $E$. \n",
    "\n",
    "---\n",
    "Validation that a single descent step $\\Delta W = -\\nabla E(W,X)$, slight side tangent (HA). \n",
    "\n",
    "So, if you remember from calc1 that $f'(x)$ is some instantaneous rate of change for some function $f$, or, more verbosely, the rate of a nudge in the function when x is nudged, or $\\dfrac{df(x)}{dx}$. Let's assume $f$ is a quadratic, nonnegative polynomial. Loosely, $\\dfrac{df(x)}{dx}$ will give us the rate at which we're moving away from the minimum of the parabola (do some slopes and plot some points, this will make sense when you draw it out). To move closer to the minimum, we have to take $-\\dfrac{df(x)}{dx}$. (We'll also have to take some learning rate $\\alpha < 1$ so we don't diverge (plot some more points for clarity). \n",
    "\n",
    "\n",
    "The way we develop a function for our error $E$ is similar. $E$ will always be non-negative (we can't have $y - \\hat{y} < 0$, because $\\hat{y}$ is some probability with a range of $[0,1]$ and $y$ is some discrete value $ y \\in \\{0,1\\}$) and we'll strive to create $E$ such that it's analagous to the bowl example above because it won't be a 3D bowl, we'll most likely deal with $E \\in \\mathbb{R} ^ n, n > 2$, a hyperdimensional bowl I guess. We'll want to move closer to the minimum of this hyperdimensional bowl so we'll need to take the negative of the rate at which $E$ is nudged when a single $w_i$ is nudged. Thus, we have $-\\dfrac{\\partial E}{\\partial w_i}, \\forall w_i \\in W = -\\nabla E(W,X)$. \n",
    "\n",
    "---\n",
    "\n",
    "So, now we'll want to **iteratively update** $W$ such that we are closer to to $\\min\\limits_{W} E$ with each step $i$, $W_{i+1} := W_i + \\Delta W_i$, where $E(W_{i+1},X) < E(W_i,X)$. However, as we saw in our 1dimensional example, we can diverge if we take too big of a nudge, so we'll have to scale down the step by some learning rate $\\alpha$, so the actual equation for an update step can be written as: $$W_{i+1} := W_i + \\alpha \\Delta W_i$$\n",
    "\n",
    "Recall that:\n",
    "* $W$ can be represented as an $n$-dimensional vector containing all the weights in a NN to parameterize.\n",
    "* $-\\nabla E$ is an $n$-dimensional vector containing the partial derivatives of each weight, i.e.: \n",
    "$$ -\\nabla E = -\\left[ \\begin{array}{ccc} \\dfrac{\\partial E}{\\partial w_1} \\\\ \\dfrac{\\partial E}{\\partial w_2} \\\\ \\vdots \\\\ \\dfrac{\\partial E}{\\partial w_n} \\end{array} \\right]$$\n",
    "\n",
    "Thus, we can represent $W + \\Delta W$ as: \n",
    "\n",
    "$$W + \\alpha \\Delta W = W -\\alpha \\nabla E = \\left[ \\begin{array}{ccc} w_1 - \\alpha\\dfrac{\\partial E}{\\partial w_1} \\\\ w_2 - \\alpha\\dfrac{\\partial E}{\\partial w_2} \\\\ \\vdots \\\\ w_n - \\alpha\\dfrac{\\partial E}{\\partial w_n} \\end{array} \\right]$$\n",
    "\n",
    "So, this begs the question: what is $\\dfrac{\\partial E}{\\partial w_i} \\forall i \\in \\{1,...,n\\}$?\n",
    "\n",
    "Recall that for 1 training example, $E = \\dfrac{1}{2}(y - \\hat{y})^2$, so let's do some math:\n",
    "\n",
    "$$ \\begin{align}\n",
    "\\dfrac{\\partial E}{\\partial w_i} &= \\dfrac{\\partial}{\\partial w_i} \\dfrac{1}{2}(y-\\hat{y})^2 \\\\ &= (y - \\hat{y})\\dfrac{\\partial}{\\partial w_i}(y - \\hat{y}) \\because \\text{ chain rule} \\\\ &= (y - \\hat{y})(0 -\\dfrac{\\partial}{\\partial w_i} \\hat{y}) \\\\ &= - (y - \\hat{y})\\dfrac{\\partial}{\\partial w_i} \\hat{y} \\\\ &= -(y-\\hat{y})\\dfrac{\\partial}{\\partial w_i} f(h), \\text{ where } h = \\sum\\limits_{i=1}^n w_i x_i\\\\ &= -(y-\\hat{y})f'(h)\\dfrac{\\partial}{\\partial w_i} \\sum\\limits_{i=1}^n w_i x_i \\because \\text{ chain rule} \\\\ &= -(y-\\hat{y})f'(h)x_i\n",
    "\\end{align}$$\n",
    "\n",
    "Thus, to perform a single update step, we'd have $\\forall w_i \\in W$:\n",
    "$$\\begin{align}\n",
    " w_i + \\alpha\\Delta w_i &= w_i + \\alpha(- \\dfrac{\\partial E}{\\partial w_i}) \\\\ &= w_i - \\alpha(-(y-\\hat{y})f'(h)x_i) \\\\ &= w_i + \\alpha(y-\\hat{y})f'(h)x_i \\\\ &= w_i + \\alpha \\delta x_i\n",
    "\\end{align}$$ \n",
    "\n",
    "where we define $\\delta = (y-\\hat{y})f'(h)$ as the 'error term'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backpropagation\n",
    "\n",
    "Through backpropagation, we feed the **error** backwords through the neural network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a neural network with 1 hidden layer, the error $\\delta$ for one hidden unit $j$ is:\n",
    "\n",
    "$$\\Large\\delta^{h}_{j} = \\sum{W_{jk}\\delta^{o}_{k}f'(h_{j})}$$\n",
    "\n",
    "* $\\delta^{h}_{j}$ is a unit $j$ in the hidden layer $h$\n",
    "* $W_{jk}$ is the weights between the hidden unit $j$ and the $k$th output unit \n",
    "* $\\delta^{o}_{k}$ is the error of the $k$th output unit \n",
    "* $f'(h_{j})$ is the derivative of the activation function \n",
    "\n",
    "---\n",
    "**BIG ISSUE RESOLVED** for the hidden layers, in order to find $\\dfrac{\\partial E}{\\partial w_j}$ where $w_j$ is some weight in a hidden layer, the equation above makes sense due to the chain rule:\n",
    "\n",
    "$$ \\begin{align}\n",
    "\\dfrac{\\partial E}{\\partial w_j} = \\left( \\dfrac{\\partial E}{\\partial f} \\right) \\left( \\dfrac{\\partial f}{\\partial w_j} \\right) \n",
    "\\end{align}$$\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "So, basically, the sum of the output errors scaled by the weights that connect the hidden unit $\\delta_j^h$ and the gradient are the total error for $\\delta_j^h$\n",
    "\n",
    "* $\\Delta w_{ij} = \\alpha \\delta_j x_i$ where $i = j-1$\n",
    "    * defining the weight update for **each unit** in the layer $j$ as the 'error term' of layer $j$ scaled by the learning rate $\\alpha$ and the activations of the previous layer (in this case, $x_i$) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python digression \n",
    "* `np.transpose(x)` for a vector is a NOOP (no-op)\n",
    "* reversed(some_list) \n",
    "    * reverses the order of elements in a list \n",
    "    * not entirely intuitive, doesn't return a list, returns a list_reverseiterator object\n",
    "* defn of a function:\n",
    "    * a self-contained block of code designed to do a specific task \n",
    "* python anonymous functions : lambda\n",
    "    * basically blocks of code that do a specific task that don't have a name \n",
    "    * `g = lambda x,y: x * y` \n",
    "        * `print(g(4,5)) # prints 20`\n",
    "    * you can put a lambda definition anywhere a function is expected\n",
    "* `sort()` sorts a function in-place and returns None\n",
    "    * python functions can return None if they're modifying the data in-space\n",
    "\n",
    "\n",
    "```python\n",
    "a = [(1, 2), (4, 1), (9, 10), (13, -3)]\n",
    "a.sort(key=lambda x: x[1])\n",
    "\n",
    "print(a)\n",
    "# Output: [(13, -3), (4, 1), (1, 2), (9, 10)]\n",
    "# Order by the second element of each tuple\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Neural Networks\n",
    "\n",
    "## Training Optimization\n",
    "\n",
    "* Basically, the big, bad world is difficult (data not that easy to understand/parse) so we'll learn how to deal with that here\n",
    "\n",
    "## Testing \n",
    "\n",
    "* We know whether a model is better than another model through training and test sets (cross-validation/dev sets in Andrew Ng's dialog)\n",
    "* Always try to go for the simpler model \n",
    "\n",
    "## Overfitting and Underfitting \n",
    "\n",
    "* Underfitting : too simple of a model\n",
    "    * doesn't have good accuracy on training set \n",
    "    * error due to bias \n",
    "* Overfitting : too specific \n",
    "    * dogs that are yellow, orange, or gray \n",
    "    * error due to variance \n",
    "    \n",
    "* studying for a test analogy:\n",
    "    * underfitting : did not study enough/not prepared \n",
    "    * overfitting : memorized word by word but did not general properly to answer test questions\n",
    "\n",
    "* hard to find a proper neural network architecture! \n",
    "    * just like trying to fit in a pair of pants \n",
    "        * get slightly bigger pants, then just wear a belt \n",
    "        * slightly more complicated-than-needed architecture that can be tuned later \n",
    "        \n",
    "## Early stopping \n",
    "\n",
    "Model Complexity Graph\n",
    "\n",
    "<img src=\"course_images/early_stopping.png\" alt=\"early stopping\" style=\"width: 50%;\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization \n",
    "\n",
    "* BertrAInd Russell \n",
    "    * \"The whole problem with AI is that bad models are so certain of themselves, and good models so full of doubts.\" \n",
    "* How do you tone down a model that is overfitting? Regularization! \n",
    "    * Penalize large weights $(w_1,...,w_n)$\n",
    "    * L1 Regularization of error function**:** $-\\dfrac{1}{m} \\sum\\limits_{i=1}^m(1-y_i)\\ln(1-\\hat{y_i})+y_iln(\\hat{y_i})+ \\boldsymbol{\\lambda (|w_1|+ ... + |w_n|)} $\n",
    "    * L2 Regularization of error function**:** $-\\dfrac{1}{m} \\sum\\limits_{i=1}^m(1-y_i)\\ln(1-\\hat{y_i})+y_iln(\\hat{y_i})+ \\boldsymbol{\\lambda (w_1^2+ ... + w_n^2)} $\n",
    "\n",
    "L1 vs L2 Regularization \n",
    "\n",
    "* L1 leads to sparse vectors, small weights will tend to go to 0\n",
    "    * good for feature selection, L1 lets us know which features are important\n",
    "* L2 maintain the weights homogeneously small\n",
    "    * noramlly better for training models \n",
    "        * homogeneity, $(0.5,0.5)$ is favored over $(0,1)$ since error gives $0.5^2 + 0.5^2 = .5$ < 1^2 + 0^2 = 1$ \n",
    "        \n",
    "## Dropout \n",
    "Dropout regularization\n",
    "\n",
    "* At times, a node or a subset of nodes in a NN will dominate the model, leaving other nodes \"not trained sufficiently\" \n",
    "    * They give an example of a person training and only getting really strong with his dominant arm (lol...)\n",
    "    \n",
    "* Now, to prevent this, we assign a probability for each node that it will be turned off for an epoch so that other nodes can have a chance to train\n",
    "    * this is called dropout regularization\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Minima \n",
    "\n",
    "* Gradient descent doesn't help at local minima (ok I think Ng disproved this for sufficiently large number of features) so we gotta find something else. \n",
    "\n",
    "## Vanishing Gradient\n",
    "* Another problem is the vanishing gradient problem \n",
    "* For example, doing backprop yields alot of chain rule:\n",
    "    * $\\dfrac{\\partial E}{\\partial W^{(1)}} = \\dfrac{\\partial E}{\\partial \\hat{y}} \\dfrac{\\partial \\hat{y}}{\\partial h} \\dfrac{\\partial h}{\\partial h_1} \\dfrac{\\partial h_1}{\\partial W^{(1)}}$\n",
    "        * If the partial derivs are small, then the product of them, yielding $\\dfrac{\\partial E}{\\partial W^{(1)}}$, is TINY\n",
    "        \n",
    "* This makes each gradient descent step small\n",
    "\n",
    "## Other Activation Functions \n",
    "\n",
    "* $\\tanh(x)$ and ReLU$(x)$\n",
    "\n",
    "* ReLU is really cool since the derivative is 1 if the number is positive \n",
    "    * fascinating that this function that barely breaks linearity can lead to complex nonlinear solutions\n",
    "    \n",
    "## Batch vs Stochastic Gradient Descent\n",
    "\n",
    "* a step is an epoch \n",
    "\n",
    "* stochastic gradient descent, just take **a subset** of the inputs, run them through the NN, calculate $- \\Delta E$, and update the weights accordingly (move one step in that direction)\n",
    "    * this subset is a batch \n",
    "    * turns out it's better to take a bunch of slightly more inaccurate steps than one good step \n",
    "    \n",
    "## Learning Rate Decay \n",
    "\n",
    "* too big of a learning rate leads to divergence, too small leads to very small steps \n",
    "    * so, general rule is:\n",
    "        * if steep: long steps \n",
    "        * if plain: small steps \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Restart \n",
    "\n",
    "* Start from a few random places and do gradient descent on all of them\n",
    "    * increases chance of getting global minimum \n",
    "    \n",
    "## Momentum \n",
    "\n",
    "* Take the average of the last few steps and use a $\\Beta$ parameter for each of the previous steps (since they don't matter as much) and use this as the next step \n",
    "    * we do this to get over \"humps\" of local minima \n",
    "\n",
    "## Error Functions Around the World\n",
    "\n",
    "* basically there's more error functions out there "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics \n",
    "\n",
    "### Confusion Matrix\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/6/6f/ConfusionMatrix.png\" alt=\"confusion matrix\" width = 50%>\n",
    "\n",
    "### Accuracy\n",
    "\n",
    "* Accuracy answers: How many were classified correctly?\n",
    "    * $\\dfrac{\\text{Positives classified correctly} + \\text{Negatives classified correctly}}{\\text{Total number in model}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When Accuracy Won't Work \n",
    "\n",
    "* Even a model that is correct $99.83%$ of the time is no good! (In the example, we didn't detect any of the spam emails)\n",
    "\n",
    "### False Negatives and Positives\n",
    "\n",
    "* We look at examples in which False Positives are worse than False Negatives and vice versa.\n",
    "\n",
    "* Warms up towards a precision and recall\n",
    "    * Medical model needs to be **high recall**\n",
    "    * Spam filter model needs to be **high precision** \n",
    "    \n",
    "### Precision \n",
    "\n",
    "* Catch out False Positives\n",
    "* Precision: Of all the points that we predict to be positive, how many were actually positive?\n",
    "    * Precision: $\\dfrac{\\text{Predicted and Actually Positive}}{\\text{Predicted Positive Actually Positive} + \\text{Predicted Positive Actually Negative}}$\n",
    "    \n",
    "### Recall \n",
    "\n",
    "* How many of the positive points did I manage to catch? \n",
    "* Catch out False Negatives\n",
    "* Recall: Of all the points that were actually positive, how many did we predict were positive?\n",
    "    * Recall: $\\dfrac{\\text{Predicted and Actually Positive}}{\\text{Predected Positive Actually Positive} + \\text{Predicted Negative Actually Positive}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Receiver Operating Characteristic (ROC) Curve \n",
    "\n",
    "* Used to evaluate a model\n",
    "* Perfect / Good / Random Split \n",
    "    * create a model such that the above is something like 1.0 / 0.8 / 0.5\n",
    "* True Positive Rate = $\\dfrac{\\text{True Positives}}{\\text{All Positives}}$\n",
    "\n",
    "\n",
    "* False Positive Rate = $\\dfrac{\\text{False Positives}}{\\text{All Negatives}}$\n",
    "\n",
    "* Move the boundary around and calculate the two rates again\n",
    "    * Plot alot of these points of these rates in a graph and measure the area under the curve\n",
    "    * Perfect split will have Area = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression \n",
    "\n",
    "### Intro \n",
    "\n",
    "* Classification answers questions like 'yes/no' (Spam/ not spam?)\n",
    "* Regression answers questions like 'how much?' (How much does this house cost?)\n",
    "\n",
    "### Quiz: Housing Prices \n",
    "\n",
    "* easy regression quiz\n",
    "\n",
    "### Fitting a Line Through Data\n",
    "\n",
    "* move a line closer to all the data points \n",
    "\n",
    "### Moving a Line \n",
    "\n",
    "* algebra \n",
    "\n",
    "### Absolute Trick \n",
    "\n",
    "* Method for moving a line closer to a point \n",
    "* $y = (w_1 + p\\alpha)x + (w_2 + \\alpha)$\n",
    "\n",
    "### Square Trick \n",
    "\n",
    "\n",
    "* Also wants a line to move closer to a point \n",
    "* $y = (w_1 + p(q-q')\\alpha)x + (w_2 +(q-q')\\alpha)$\n",
    "\n",
    "\n",
    "### Gradient Descent \n",
    "\n",
    "* motivation for using gradient descent for regression\n",
    "\n",
    "### Mean Absolute Error \n",
    "\n",
    "* Funtions for formulating error functions (with which you'd want to walk down using things gradient descent)\n",
    "* $E = \\dfrac{1}{m}\\sum\\limits_{i=1}^m|y-\\hat{y}|$\n",
    "\n",
    "### Mean Squared Error \n",
    "\n",
    "* $E = \\dfrac{1}{2m}\\sum\\limits_{i=1}^m(y-\\hat{y})^2$\n",
    "\n",
    "### Minimizing Error Functions \n",
    "\n",
    "* Tricks the same as Error minimizations \n",
    "* Derives that:\n",
    "    * $\\dfrac{\\partial E}{\\partial w_1} = -(y-\\hat{y})x$  \n",
    "    * $\\dfrac{\\partial E}{\\partial w_2} = -(y-\\hat{y})$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean vs Total Squared (or Absolute) Error \n",
    "\n",
    "* when should we use the total squared error vs the mean? (aka the $\\dfrac{1}{m}$ factor)\n",
    "* doesn't really matter! The learning rate $\\alpha$ will factor it out anyway \n",
    "\n",
    "### Batch vs Stochastic Gradient Descent \n",
    "\n",
    "* Stochastic Gradient Descent \n",
    "    * applying error minimization to every point in our data *one by one*, and repeating this process many times \n",
    "* Batch Gradient Descent\n",
    "    * applying error minimization to every point in our data *all at the same time*, and repeating this process many times\n",
    "    \n",
    "    \n",
    "* **Mini batch gradient descent** is the best way to go for fastest, most efficient computational time    \n",
    "\n",
    "### Absolute Error vs Squared Error\n",
    "\n",
    "* mean squared error can better find the line of best fit for a model, at least for the example shown\n",
    "\n",
    "### Closed Form Solution \n",
    "\n",
    "* too computationally expensive, iterative solution through methods like gradient descent are better \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Warnings\n",
    "\n",
    "* Linear Regression Works best when the data is linear\n",
    "* Linear Regression is sensitive to outliers\n",
    "\n",
    "### Polynomial Regression\n",
    "\n",
    "* same principle! Just use Mean Squared Error on a more complex polynomial function and use gradient descent to update the weights\n",
    "\n",
    "### Regularization\n",
    "\n",
    "* Motivation: you want the complexity of the model to be added into the error \n",
    "    * simpler models tend to generalize better, so we want a mixture of both error of the actual prediction + measure of complexity of the model\n",
    "\n",
    "* complexity of a model is correlated to the weights $(w_1,...,w_n)$\n",
    "\n",
    "* Simple vs Complex models \n",
    "    * models that are ok to be complex: rocket models, medical models\n",
    "        * less punishment for complexity\n",
    "    * models that are ok to be simpler: social media models, recommender systems  \n",
    "        * more punishment for complexity \n",
    "    \n",
    "* $\\lambda$ is the regularization parameter\n",
    "    * larger $\\lambda$ means more punishment on complexity \n",
    "        \n",
    "* L1 vs L2\n",
    "\n",
    "| L1 Regularization           | L2 Regularization        |\n",
    "|-----------------------------|--------------------------|\n",
    "|Computationally Inefficient  | Computationally Efficient|\n",
    "|Sparse Outputs               | Non-Sparse Outputs       |\n",
    "|Feature Selection            |No Feature Selection      |\n",
    "\n",
    "\n",
    "\n",
    "### Neural Network Regression\n",
    "\n",
    "* To use neural networks for regression, just remove the final activation function (that gives a number between 0 and 1) to give any output number, use the same error function as you did for the classification problem (true?), and voila! you have a NN regression model.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
